<h2>Speech Emotion Recognition using Bi-Directional LSTM</h2>

<h4>
Speech is unique, it is generated by communicative intentions of the speaker to whom they talk to. The speaker cannot hide their emotion from their voice except they pretend to do it. So, we can use a Speech Emotion Recognition (SER), a computational method to recognize human emotion from the speech sound. Our SER system will categorize the speech as per six categories of emotions; “Sadness”, “Love”, “Anger”, “Joy”, “Fear”, and “Surprise”.

We have taken the datasets for this project from Kaggle. This dataset contains around 20000 records in different text files for training, testing and validation. All records in the dataset are labelled into six categories of emotions.
</h4>
<h4> Link to the Model Trained :- <a href="https://drive.google.com/drive/folders/1l49vAH9dyEgDLvdnSN8Ycz5ycOTqAQB_?usp=sharing"> Click Here </a></h4>
<h3> Working Video of Our Project </h3>
<img src="https://github.com/g2000p/Speech_Emotion_Recognition/blob/main/static/img/gifti.gif">

